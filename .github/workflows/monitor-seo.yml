name: Monitor SEO Multi-Sites

on:
  schedule:
    - cron: '0 8,20 * * *'
  workflow_dispatch:
    inputs:
      site_filter:
        description: 'Nom du site à tester (vide = tous)'
        required: false
        default: ''
      force_alert:
        description: 'Forcer envoi email'
        required: false
        default: 'false'

env:
  EMAIL_USERNAME: 'vbouvier.redactrice@gmail.com'
  EMAIL_PASSWORD: 'avrf enpz otim qlnf'
  NOTIFICATION_EMAIL: 'vbouvier@cybercite.fr'

jobs:
  setup:
    name: Configuration
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      sites_count: ${{ steps.set-matrix.outputs.count }}
    
    steps:
    - name: Configure sites matrix
      id: set-matrix
      run: |
        SITES_JSON=$(cat << 'EOF'
        {
          "sites": [
            {
              "name": "Brown Shipley",
              "url": "https://brownshipley.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["en-gb/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Orange Caraibe",
              "url": "https://caraibe.orange.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Recrutement FHSJ",
              "url": "https://recrutement-fhsj.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Assuropoil",
              "url": "https://www.assuropoil.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Avoriaz",
              "url": "https://www.avoriaz.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Domicile Clean",
              "url": "https://www.domicile-clean.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Espaces Atypiques",
              "url": "https://www.espaces-atypiques.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Hopital Marie Lannelongue",
              "url": "https://www.hopitalmarielannelongue.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "HPSJ",
              "url": "https://www.hpsj.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "InsingerGilissen",
              "url": "https://www.insingergilissen.nl/",
              "robots_path": "nl-nl/robots.txt",
              "sitemaps": ["nl-nl/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "International Patient Paris",
              "url": "https://www.international-patient-paris.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Le Voyage a Nantes",
              "url": "https://www.levoyageanantes.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Macoretz",
              "url": "https://www.macoretz.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Merck Finck",
              "url": "https://www.merckfinck.de/",
              "robots_path": "robots.txt",
              "sitemaps": ["de-de/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "NDBS",
              "url": "https://www.ndbs.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Pharmapets BE",
              "url": "https://www.pharmapets.be/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/pharmapets_be/sitemap_nl_product.xml",
                "media/sitemaps/pharmapets_be/sitemap_fr_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Pharmapets NL",
              "url": "https://www.pharmapets.nl/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/pharmapets_nl/sitemap_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Puilaetco",
              "url": "https://www.puilaetco.be/",
              "robots_path": "robots.txt",
              "sitemaps": ["fr-be/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Quintet COM",
              "url": "https://www.quintet.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["en-gb/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Quintet LU",
              "url": "https://www.quintet.lu/",
              "robots_path": "robots.txt",
              "sitemaps": ["en-lu/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Royan Atlantique",
              "url": "https://www.royanatlantique.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Sayse",
              "url": "https://www.sayse.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Terre de Marins",
              "url": "https://www.terredemarins.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["1_fr_0_sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Tom and Co",
              "url": "https://www.tomandco.com/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/tomandco/sitemap_tc_benl_product.xml",
                "media/sitemaps/tomandco/sitemap_tc_befr_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Vetostore",
              "url": "https://www.vetostore.com/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/vetostore/sitemap_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Lea Nature",
              "url": "https://www.leanature.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["media/google_sitemap_3.xml"],
              "enabled": true
            }
          ]
        }
        EOF
        )
        
        if [ -n "${{ github.event.inputs.site_filter }}" ]; then
          FILTERED=$(echo "$SITES_JSON" | jq -c --arg filter "${{ github.event.inputs.site_filter }}" '.sites | map(select(.name | test($filter; "i")) | select(.enabled == true))')
        else
          FILTERED=$(echo "$SITES_JSON" | jq -c '.sites | map(select(.enabled == true))')
        fi
        
        echo "matrix={\"include\":$FILTERED}" >> $GITHUB_OUTPUT
        COUNT=$(echo "$FILTERED" | jq '. | length')
        echo "count=$COUNT" >> $GITHUB_OUTPUT
        echo "$COUNT sites configurés"

  monitor:
    name: Monitor ${{ matrix.name }}
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}
      max-parallel: 5
      fail-fast: false
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup
      run: |
        SAFE_NAME=$(echo "${{ matrix.name }}" | sed 's/[^a-zA-Z0-9]/_/g' | tr '[:upper:]' '[:lower:]')
        echo "SAFE_NAME=${SAFE_NAME}" >> $GITHUB_ENV
        mkdir -p "data/${SAFE_NAME}"
        mkdir -p "history/${SAFE_NAME}"
        mkdir -p "changes/${SAFE_NAME}"
    
    - name: Download robots.txt
      id: robots
      run: |
        URL="${{ matrix.url }}${{ matrix.robots_path }}"
        echo "Robots.txt: $URL"
        
        HTTP_STATUS=$(curl -s -o "data/${SAFE_NAME}/robots.txt" -w "%{http_code}" -L "$URL" \
          -H "User-Agent: Mozilla/5.0 (compatible; SEOMonitor/1.0)" \
          --max-time 30)
        
        if [ "$HTTP_STATUS" -eq 200 ]; then
          echo "OK ($(wc -l < data/${SAFE_NAME}/robots.txt) lignes)"
          echo "status=success" >> $GITHUB_OUTPUT
        else
          echo "Erreur HTTP $HTTP_STATUS"
          echo "status=error" >> $GITHUB_OUTPUT
          echo "error=HTTP $HTTP_STATUS" >> $GITHUB_OUTPUT
        fi
    
    - name: Download sitemaps
      id: sitemaps
      run: |
        echo "Téléchargement des sitemaps..."
        echo "success" > /tmp/sitemap_status.txt
        echo "" > /tmp/sitemap_errors.txt
        
        echo '${{ toJson(matrix.sitemaps) }}' | jq -r '.[]' | while IFS= read -r sitemap; do
          URL="${{ matrix.url }}${sitemap}"
          FILENAME=$(echo "$sitemap" | sed 's/\//_/g')
          
          echo "  -> $URL"
          HTTP_STATUS=$(curl -s -o "data/${SAFE_NAME}/sitemap_${FILENAME}" -w "%{http_code}" -L "$URL" \
            -H "User-Agent: Mozilla/5.0 (compatible; SEOMonitor/1.0)" \
            --max-time 30)
          
          if [ "$HTTP_STATUS" -eq 200 ]; then
            echo "    OK ($(wc -c < data/${SAFE_NAME}/sitemap_${FILENAME}) bytes)"
          else
            echo "    Erreur HTTP $HTTP_STATUS"
            echo "error" > /tmp/sitemap_status.txt
            echo "${sitemap}:${HTTP_STATUS};" >> /tmp/sitemap_errors.txt
          fi
        done
        
        STATUS=$(cat /tmp/sitemap_status.txt)
        ERRORS=$(cat /tmp/sitemap_errors.txt | tr -d '\n')
        
        echo "status=$STATUS" >> $GITHUB_OUTPUT
        echo "errors=$ERRORS" >> $GITHUB_OUTPUT
    
    - name: Setup initial state and restore history
      id: setup_state
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Initialisation de l'état..."
        mkdir -p "history/${SAFE_NAME}"
        
        echo "Recherche et récupération de l'historique pour: ${SAFE_NAME}"
        
        # Récupérer les 10 derniers runs complétés
        RECENT_RUNS=$(gh run list --repo ${{ github.repository }} --status completed --limit 10 --json number --jq '.[].number')
        
        HISTORY_FOUND=false
        
        for run_number in $RECENT_RUNS; do
          echo "Test run #$run_number..."
          
          # Essayer directement de télécharger l'artifact
          if gh run download "$run_number" --repo ${{ github.repository }} --name "history-${SAFE_NAME}" --dir "temp_${run_number}" >/dev/null 2>&1; then
            echo "Historique trouvé dans run #$run_number"
            
            # Vérifier et copier les fichiers
            if [ -d "temp_${run_number}" ] && [ "$(ls -A temp_${run_number} 2>/dev/null)" ]; then
              cp -r temp_${run_number}/* "history/${SAFE_NAME}/" 2>/dev/null || true
              
              # Vérifier la restauration
              if [ -f "history/${SAFE_NAME}/.last_check" ] || [ -f "history/${SAFE_NAME}/robots.txt" ]; then
                echo "Historique restauré avec succès"
                HISTORY_FOUND=true
                rm -rf "temp_${run_number}"
                break
              fi
            fi
            
            rm -rf "temp_${run_number}"
          fi
        done
        
        # Résultat final
        if [ "$HISTORY_FOUND" = "true" ]; then
          echo "has_history=true" >> $GITHUB_OUTPUT
        else
          echo "Aucun historique trouvé - première exécution"
          echo "has_history=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Determine execution type
      id: execution_type
      run: |
        if [ "${{ steps.setup_state.outputs.has_history }}" = "true" ]; then
          echo "Historique trouvé - comparaison activée"
          echo "is_first_run=false" >> $GITHUB_OUTPUT
        else
          echo "Première exécution - création de l'état initial"
          echo "is_first_run=true" >> $GITHUB_OUTPUT
        fi
    
    - name: Check for changes
      id: changes
      run: |
        echo "Analyse des changements..."
        
        IS_FIRST_RUN="${{ steps.execution_type.outputs.is_first_run }}"
        HAS_CHANGES=false
        CHANGES_DETAILS=""
        
        if [ "$IS_FIRST_RUN" = "true" ]; then
          echo "Première vérification pour ce site"
        else
          echo "Comparaison avec l'historique..."
          
          if [ -f "data/${SAFE_NAME}/robots.txt" ] && [ -f "history/${SAFE_NAME}/robots.txt" ]; then
            if ! diff -q "history/${SAFE_NAME}/robots.txt" "data/${SAFE_NAME}/robots.txt" > /dev/null; then
              HAS_CHANGES=true
              echo "Changements détectés dans robots.txt"
              
              diff -u "history/${SAFE_NAME}/robots.txt" "data/${SAFE_NAME}/robots.txt" > "changes/${SAFE_NAME}/robots_diff.txt" || true
              
              ADDED_LINES=$(grep "^+" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^+++" | wc -l || echo 0)
              REMOVED_LINES=$(grep "^-" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^---" | wc -l || echo 0)
              
              echo "### ROBOTS.TXT CHANGES ###" > "changes/${SAFE_NAME}/robots_changes.txt"
              echo "Lignes ajoutées: $ADDED_LINES" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "Lignes supprimées: $REMOVED_LINES" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "=== AJOUTS ===" >> "changes/${SAFE_NAME}/robots_changes.txt"
              grep "^+" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^+++" | head -20 >> "changes/${SAFE_NAME}/robots_changes.txt" || true
              echo "" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "=== SUPPRESSIONS ===" >> "changes/${SAFE_NAME}/robots_changes.txt"
              grep "^-" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^---" | head -20 >> "changes/${SAFE_NAME}/robots_changes.txt" || true
              
              CHANGES_DETAILS="${CHANGES_DETAILS}robots.txt:modified($ADDED_LINES+/$REMOVED_LINES-);"
            fi
          fi
          
          for sitemap_file in data/${SAFE_NAME}/sitemap_*; do
            if [ -f "$sitemap_file" ]; then
              BASENAME=$(basename "$sitemap_file")
              
              if [ -f "history/${SAFE_NAME}/$BASENAME" ]; then
                if ! diff -q "$sitemap_file" "history/${SAFE_NAME}/$BASENAME" > /dev/null; then
                  HAS_CHANGES=true
                  echo "Changements dans $BASENAME"
                  
                  if [[ "$BASENAME" == *".xml" ]]; then
                    grep -o '<loc>[^<]*</loc>' "history/${SAFE_NAME}/$BASENAME" 2>/dev/null | sed 's/<[^>]*>//g' | sort > "/tmp/old_urls.txt" || touch "/tmp/old_urls.txt"
                    grep -o '<loc>[^<]*</loc>' "$sitemap_file" | sed 's/<[^>]*>//g' | sort > "/tmp/new_urls.txt"
                    
                    ADDED_URLS=$(comm -13 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | wc -l)
                    REMOVED_URLS=$(comm -23 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | wc -l)
                    
                    echo "### $BASENAME CHANGES ###" > "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    echo "URLs ajoutées: $ADDED_URLS" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    echo "URLs supprimées: $REMOVED_URLS" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    echo "" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    
                    if [ $ADDED_URLS -gt 0 ]; then
                      echo "=== NOUVELLES URLS ===" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                      comm -13 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | head -10 >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    fi
                    
                    if [ $REMOVED_URLS -gt 0 ]; then
                      echo "=== URLS SUPPRIMÉES ===" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                      comm -23 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | head -10 >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    fi
                    
                    CHANGES_DETAILS="${CHANGES_DETAILS}${BASENAME}:modified($ADDED_URLS+/$REMOVED_URLS-);"
                  fi
                fi
              fi
            fi
          done
        fi
        
        echo "is_first_run=$IS_FIRST_RUN" >> $GITHUB_OUTPUT
        echo "has_changes=$HAS_CHANGES" >> $GITHUB_OUTPUT
        echo "details=$CHANGES_DETAILS" >> $GITHUB_OUTPUT
    
    - name: Create detailed report
      id: report
      run: |
        REPORT_FILE="data/${SAFE_NAME}/report.json"
        
        cat << EOF > "$REPORT_FILE"
        {
          "site": "${{ matrix.name }}",
          "url": "${{ matrix.url }}",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "is_first_run": ${{ steps.changes.outputs.is_first_run }},
          "robots": {
            "status": "${{ steps.robots.outputs.status }}",
            "error": "${{ steps.robots.outputs.error }}"
          },
          "sitemaps": {
            "status": "${{ steps.sitemaps.outputs.status }}",
            "errors": "${{ steps.sitemaps.outputs.errors }}"
          },
          "changes": {
            "has_changes": ${{ steps.changes.outputs.has_changes }},
            "details": "${{ steps.changes.outputs.details }}"
          }
        }
        EOF
        
        if [ -d "changes/${SAFE_NAME}" ] && [ "$(ls -A changes/${SAFE_NAME})" ]; then
          echo "Détails des changements disponibles"
          tar -czf "data/${SAFE_NAME}/changes.tar.gz" -C "changes/${SAFE_NAME}" .
        fi
        
        NEEDS_ALERT=false
        if [ "${{ steps.robots.outputs.status }}" = "error" ] || \
           [ "${{ steps.sitemaps.outputs.status }}" = "error" ] || \
           [ "${{ steps.changes.outputs.has_changes }}" = "true" ]; then
          NEEDS_ALERT=true
        fi
        
        echo "needs_alert=$NEEDS_ALERT" >> $GITHUB_OUTPUT
    
    - name: Save history
      if: always()
      run: |
        echo "Sauvegarde de l'état actuel..."
        
        mkdir -p "history/${SAFE_NAME}"
        
        echo "$(date -u +%Y-%m-%dT%H:%M:%SZ)" > "history/${SAFE_NAME}/.last_check"
        
        if [ -f "data/${SAFE_NAME}/robots.txt" ] && [ "${{ steps.robots.outputs.status }}" = "success" ]; then
          cp "data/${SAFE_NAME}/robots.txt" "history/${SAFE_NAME}/robots.txt"
          echo "robots.txt sauvegardé"
        else
          echo "robots.txt non sauvegardé (erreur: ${{ steps.robots.outputs.status }})"
        fi
        
        SITEMAP_COUNT=0
        for sitemap in data/${SAFE_NAME}/sitemap_*; do
          if [ -f "$sitemap" ]; then
            cp "$sitemap" "history/${SAFE_NAME}/"
            SITEMAP_COUNT=$((SITEMAP_COUNT + 1))
          fi
        done
        echo "$SITEMAP_COUNT sitemaps sauvegardés"
        
        if [ -f "history/${SAFE_NAME}/.last_check" ]; then
          echo "Dossier historique prêt pour upload"
          ls -la "history/${SAFE_NAME}/"
        else
          echo "Problème avec la création du dossier historique"
        fi
    
    - name: Upload history
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: history-${{ env.SAFE_NAME }}
        path: history/${{ env.SAFE_NAME }}/
        retention-days: 30
        if-no-files-found: ignore
    
    - name: Upload report and changes
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: report-${{ env.SAFE_NAME }}
        path: |
          data/${{ env.SAFE_NAME }}/report.json
          data/${{ env.SAFE_NAME }}/changes.tar.gz
        retention-days: 7
        if-no-files-found: ignore

  commit_history:
    name: Commit History
    needs: [setup, monitor]
    runs-on: ubuntu-latest
    if: always()
    permissions:
      contents: write
      actions: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
    
    - name: Download all reports
      uses: actions/download-artifact@v4
      with:
        pattern: report-*
        path: reports/
      continue-on-error: true
    
    - name: Rebuild SEO history from current data
      run: |
        echo "Reconstruction de l'historique SEO..."
        
        # Créer le dossier d'historique s'il n'existe pas
        mkdir -p .seo-history
        
        # Créer un fichier README pour expliquer le dossier
        cat > .seo-history/README.md << 'EOF'
        # SEO History
        
        Ce dossier contient l'historique des fichiers robots.txt et sitemaps pour le monitoring SEO.
        
        Structure:
        - Chaque sous-dossier correspond à un site surveillé
        - `.last_check` : timestamp de la dernière vérification
        - `robots.txt` : dernière version du fichier robots.txt
        - `sitemap_*.xml` : derniers sitemaps téléchargés
        
        Généré automatiquement par GitHub Actions.
        EOF
        
        # Traiter chaque rapport pour reconstruire l'historique de chaque site
        for report_dir in reports/report-*; do
          if [ -d "$report_dir" ] && [ -f "$report_dir/report.json" ]; then
            # Extraire le nom du site depuis le nom du dossier
            SITE_DIR=$(basename "$report_dir" | sed 's/report-//')
            echo "Préparation historique pour: $SITE_DIR"
            
            # Créer le dossier d'historique pour ce site
            mkdir -p ".seo-history/${SITE_DIR}"
            
            # Créer le marker avec timestamp
            echo "$(date -u +%Y-%m-%dT%H:%M:%SZ)" > ".seo-history/${SITE_DIR}/.last_check"
            
            # Ajouter une note d'information
            echo "Site surveillé: $(jq -r '.site // "Unknown"' "$report_dir/report.json" 2>/dev/null)" > ".seo-history/${SITE_DIR}/info.txt"
          fi
        done
        
        echo "Structure d'historique créée"
    
  commit_history:
    name: Commit History
    needs: [setup, monitor]
    runs-on: ubuntu-latest
    if: always()
    permissions:
      contents: write
      actions: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
    
    - name: Download all reports
      uses: actions/download-artifact@v4
      with:
        pattern: report-*
        path: reports/
      continue-on-error: true
    
    - name: Rebuild SEO history from current data
      run: |
        echo "Reconstruction de l'historique SEO..."
        
        # Créer le dossier d'historique s'il n'existe pas
        mkdir -p .seo-history
        
        # Créer un fichier README pour expliquer le dossier
        cat > .seo-history/README.md << 'EOF'
        # SEO History
        
        Ce dossier contient l'historique des fichiers robots.txt et sitemaps pour le monitoring SEO.
        
        Structure:
        - Chaque sous-dossier correspond à un site surveillé
        - `.last_check` : timestamp de la dernière vérification
        - `robots.txt` : dernière version du fichier robots.txt
        - `sitemap_*.xml` : derniers sitemaps téléchargés
        
        Généré automatiquement par GitHub Actions.
        EOF
        
        # Traiter chaque rapport pour reconstruire l'historique de chaque site
        for report_dir in reports/report-*; do
          if [ -d "$report_dir" ] && [ -f "$report_dir/report.json" ]; then
            # Extraire le nom du site depuis le nom du dossier
            SITE_DIR=$(basename "$report_dir" | sed 's/report-//')
            echo "Préparation historique pour: $SITE_DIR"
            
            # Créer le dossier d'historique pour ce site
            mkdir -p ".seo-history/${SITE_DIR}"
            
            # Créer le marker avec timestamp
            echo "$(date -u +%Y-%m-%dT%H:%M:%SZ)" > ".seo-history/${SITE_DIR}/.last_check"
            
            # Ajouter une note d'information
            echo "Site surveillé: $(jq -r '.site // "Unknown"' "$report_dir/report.json" 2>/dev/null)" > ".seo-history/${SITE_DIR}/info.txt"
          fi
        done
        
        echo "Structure d'historique créée localement"
    
    - name: Commit and push history with sync
      run: |
        echo "Synchronisation et commit de l'historique..."
        
        # Configurer Git
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Synchroniser avec la branche distante avant de commiter
        echo "Synchronisation avec la branche distante..."
        git fetch origin
        git rebase origin/main || {
          echo "Conflit détecté, tentative de résolution automatique..."
          git rebase --abort
          git reset --hard origin/main
          echo "Reset effectué, reconstruction de l'historique..."
        }
        
        # Reconstruire l'historique après sync
        mkdir -p .seo-history
        
        # Créer/Mettre à jour le README
        cat > .seo-history/README.md << 'EOF'
# SEO History

Ce dossier contient l'historique des fichiers robots.txt et sitemaps pour le monitoring SEO.

Structure:
- Chaque sous-dossier correspond à un site surveillé
- `.last_check` : timestamp de la dernière vérification
- `robots.txt` : dernière version du fichier robots.txt
- `sitemap_*.xml` : derniers sitemaps téléchargés

Généré automatiquement par GitHub Actions.
EOF

        # Recréer l'historique pour tous les sites
        for report_dir in reports/report-*; do
          if [ -d "$report_dir" ] && [ -f "$report_dir/report.json" ]; then
            SITE_DIR=$(basename "$report_dir" | sed 's/report-//')
            mkdir -p ".seo-history/${SITE_DIR}"
            echo "$(date -u +%Y-%m-%dT%H:%M:%SZ)" > ".seo-history/${SITE_DIR}/.last_check"
            echo "Site surveillé: $(jq -r '.site // "Unknown"' "$report_dir/report.json" 2>/dev/null)" > ".seo-history/${SITE_DIR}/info.txt"
          fi
        done
        
        # Ajouter tous les fichiers d'historique
        git add .seo-history/
        
        # Vérifier s'il y a des changements à commiter
        if git diff --staged --quiet; then
          echo "Aucun changement d'historique à commiter après sync"
        else
          echo "Changements détectés après sync, commit en cours..."
          
          # Commit avec message unique basé sur timestamp
          TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)
          if git commit -m "Update SEO history structure - ${TIMESTAMP}"; then
            echo "Commit réussi, tentative de push..."
            
            # Push avec retry en cas d'échec
            MAX_RETRIES=3
            RETRY_COUNT=0
            
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              if git push origin main; then
                echo "Push réussi - historique sauvegardé"
                break
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                echo "Push échoué, tentative $RETRY_COUNT/$MAX_RETRIES"
                
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  echo "Nouvelle synchronisation avant retry..."
                  git fetch origin
                  git rebase origin/main || {
                    echo "Conflit lors du retry, abandon du push"
                    echo "L'historique est créé localement pour ce run"
                    break
                  }
                  sleep 2
                else
                  echo "Échec du push après $MAX_RETRIES tentatives"
                  echo "L'historique reste disponible localement pour ce run"
                fi
              fi
            done
          else
            echo "Aucun changement réel à commiter après sync"
          fi
        fi

  notify:
    name: Notification
    needs: [setup, monitor, commit_history]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Download all reports
      uses: actions/download-artifact@v4
      with:
        pattern: report-*
        path: reports/
      continue-on-error: true
    
    - name: Analyze and prepare notification
      id: analyze
      run: |
        echo "Analyse des rapports..."
        
        TOTAL="${{ needs.setup.outputs.sites_count }}"
        FIRST_RUN=0
        WITH_CHANGES=0
        WITH_ERRORS=0
        NEEDS_EMAIL=false
        
        if [ ! -d "reports" ]; then
          echo "Aucun rapport téléchargé, création d'un dossier vide"
          mkdir -p reports
        fi
        
        for report_dir in reports/report-*; do
          if [ -d "$report_dir" ] && [ -f "$report_dir/report.json" ]; then
            REPORT=$(cat "$report_dir/report.json")
            
            IS_FIRST=$(echo "$REPORT" | jq -r '.is_first_run')
            HAS_CHANGES=$(echo "$REPORT" | jq -r '.changes.has_changes')
            ROBOTS_ERROR=$(echo "$REPORT" | jq -r '.robots.status')
            SITEMAP_ERROR=$(echo "$REPORT" | jq -r '.sitemaps.status')
            
            if [ "$IS_FIRST" = "true" ]; then
              FIRST_RUN=$((FIRST_RUN + 1))
            elif [ "$HAS_CHANGES" = "true" ]; then
              WITH_CHANGES=$((WITH_CHANGES + 1))
              NEEDS_EMAIL=true
            fi
            
            if [ "$ROBOTS_ERROR" = "error" ] || [ "$SITEMAP_ERROR" = "error" ]; then
              WITH_ERRORS=$((WITH_ERRORS + 1))
              NEEDS_EMAIL=true
            fi
            
            if [ -f "$report_dir/changes.tar.gz" ]; then
              mkdir -p "all_changes/$(basename $report_dir)"
              tar -xzf "$report_dir/changes.tar.gz" -C "all_changes/$(basename $report_dir)"
            fi
          fi
        done
        
        if [ "${{ github.event.inputs.force_alert }}" = "true" ]; then
          NEEDS_EMAIL=true
        fi
        
        echo "first_run=$FIRST_RUN" >> $GITHUB_OUTPUT
        echo "with_changes=$WITH_CHANGES" >> $GITHUB_OUTPUT
        echo "with_errors=$WITH_ERRORS" >> $GITHUB_OUTPUT
        echo "needs_email=$NEEDS_EMAIL" >> $GITHUB_OUTPUT
        
        echo "# Monitoring SEO - Résumé" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Sites surveillés:** $TOTAL" >> $GITHUB_STEP_SUMMARY
        echo "- **Première vérification:** $FIRST_RUN" >> $GITHUB_STEP_SUMMARY
        echo "- **Avec changements:** $WITH_CHANGES" >> $GITHUB_STEP_SUMMARY
        echo "- **Avec erreurs:** $WITH_ERRORS" >> $GITHUB_STEP_SUMMARY

    - name: Send detailed email
      if: steps.analyze.outputs.needs_email == 'true'
      env:
        GITHUB_REPOSITORY: ${{ github.repository }}
        GITHUB_RUN_ID: ${{ github.run_id }}
      run: |
        python3 << 'PYTHON'
        import smtplib
        import json
        import os
        from email.mime.text import MIMEText
        from email.mime.multipart import MIMEMultipart
        from datetime import datetime
        
        print("Préparation de l'email de notification...")
        
        sender = "${{ env.EMAIL_USERNAME }}"
        password = "${{ env.EMAIL_PASSWORD }}"
        receiver = "${{ env.NOTIFICATION_EMAIL }}"
        
        total = int("${{ needs.setup.outputs.sites_count }}")
        first_run = int("${{ steps.analyze.outputs.first_run }}")
        with_changes = int("${{ steps.analyze.outputs.with_changes }}")
        with_errors = int("${{ steps.analyze.outputs.with_errors }}")
        
        print(f"Statistiques: {total} sites, {first_run} premières exécutions, {with_changes} changements, {with_errors} erreurs")        
        
        if with_errors > 0:
            subject = f"SEO Alert - {with_errors} erreur(s) / {total} sites"
        elif with_changes > 0:
            subject = f"SEO Update - {with_changes} changement(s) / {total} sites"
        else:
            subject = f"SEO Check - {total} sites vérifiés"
        
        html = f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; }}
                .header {{ background: #f8f9fa; padding: 20px; border-radius: 5px; }}
                .summary {{ background: #e9ecef; padding: 15px; margin: 20px 0; border-radius: 5px; }}
                .site {{ margin: 20px 0; padding: 15px; border-left: 4px solid #007bff; background: #f9f9f9; }}
                .site-error {{ border-left-color: #dc3545; background: #f8d7da; }}
                .site-changed {{ border-left-color: #ffc107; background: #fff3cd; }}
                .site-new {{ border-left-color: #17a2b8; background: #d1ecf1; }}
                .changes-detail {{ background: white; padding: 10px; margin: 10px 0; border-radius: 3px; font-family: monospace; font-size: 12px; }}
                .footer {{ margin-top: 30px; padding-top: 20px; border-top: 1px solid #dee2e6; color: #6c757d; font-size: 0.9em; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Monitoring SEO Multi-Sites</h1>
                <p><strong>Date:</strong> {datetime.now().strftime("%d/%m/%Y %H:%M")}</p>
             <p><strong>Repository:</strong> {os.environ.get('GITHUB_REPOSITORY', 'N/A')}</p>
            </div>
            
            <div class="summary">
                <h2>Résumé</h2>
                <ul>
                    <li><strong>Sites surveillés:</strong> {total}</li>
                    <li><strong>Première vérification:</strong> {first_run}</li>
                    <li><strong>Avec changements:</strong> {with_changes}</li>
                    <li><strong>Avec erreurs:</strong> {with_errors}</li>
                </ul>
            </div>
            
            <h2>Détails par site</h2>
        """
        
        if os.path.exists("reports"):
            for report_dir in os.listdir("reports"):
                if report_dir.startswith("report-"):
                    report_path = os.path.join("reports", report_dir, "report.json")
                    if os.path.exists(report_path):
                        with open(report_path) as f:
                            report = json.load(f)
                        
                        has_errors = (report['robots']['status'] == 'error' or report['sitemaps']['status'] == 'error')
                        has_changes = (report['changes']['has_changes'] == True)
                        is_first_run = report['is_first_run']
                        
                        if has_errors or (has_changes and not is_first_run):
                            if has_errors:
                                if is_first_run:
                                    site_class = 'site-error'
                                    icon = '🚨'
                                else:
                                    site_class = 'site-error' 
                                    icon = '❌'
                            elif has_changes:
                                site_class = 'site-changed'
                                icon = '📝'
                            
                            html += f'<div class="{site_class}">'
                            if is_first_run and has_errors:
                                html += f'<h3>{icon} {report["site"]} <span style="color: #6c757d; font-size: 0.8em;">(Première vérification)</span></h3>'
                            else:
                                html += f'<h3>{icon} {report["site"]}</h3>'
                            html += f'<p><strong>URL:</strong> <a href="{report["url"]}">{report["url"]}</a></p>'
                            
                            if report['robots']['status'] == 'error':
                                error_msg = report['robots'].get('error', 'Erreur inconnue')
                                html += f'<p>⚠️ <strong>robots.txt:</strong> {error_msg}</p>'
                            
                            if report['sitemaps']['status'] == 'error':
                                error_msg = report['sitemaps'].get('errors', 'Erreur inconnue')
                                html += f'<p>⚠️ <strong>sitemaps:</strong> {error_msg}</p>'
                            
                            if has_changes and not is_first_run and report['changes']['details']:
                                html += '<div class="changes-detail">'
                                html += '<strong>Changements détectés:</strong><br>'
                                
                                details = report['changes']['details']
                                for change in details.split(';'):
                                    if change:
                                        parts = change.split(':')
                                        if len(parts) == 2:
                                            file_name = parts[0]
                                            change_info = parts[1]
                                            
                                            if 'modified' in change_info and '(' in change_info:
                                                nums = change_info[change_info.find('(')+1:change_info.find(')')].split('/')
                                                if len(nums) == 2:
                                                    added = nums[0].replace('+', '')
                                                    removed = nums[1].replace('-', '')
                                                    
                                                    if file_name == 'robots.txt':
                                                        html += f'<br>📄 <strong>robots.txt:</strong> '
                                                        html += f'{added} lignes ajoutées, {removed} lignes supprimées'
                                                    elif 'sitemap' in file_name:
                                                        html += f'<br>🗺️ <strong>{file_name}:</strong> '
                                                        html += f'{added} URLs ajoutées, {removed} URLs supprimées'
                                
                                changes_dir = f"all_changes/report-{report['site'].replace(' ', '_').lower()}"
                                if os.path.exists(changes_dir):
                                    robots_changes = os.path.join(changes_dir, "robots_changes.txt")
                                    if os.path.exists(robots_changes):
                                        with open(robots_changes) as f:
                                            content = f.read()
                                            if '=== AJOUTS ===' in content:
                                                adds = content.split('=== AJOUTS ===')[1].split('=== SUPPRESSIONS ===')[0].strip()
                                                if adds:
                                                    html += '<br><br><strong>Lignes ajoutées dans robots.txt:</strong><br>'
                                                    for line in adds.split('\n')[:5]:
                                                        if line.strip():
                                                            html += f'<code>+ {line.strip()}</code><br>'
                                            
                                            if '=== SUPPRESSIONS ===' in content:
                                                dels = content.split('=== SUPPRESSIONS ===')[1].strip()
                                                if dels:
                                                    html += '<br><strong>Lignes supprimées dans robots.txt:</strong><br>'
                                                    for line in dels.split('\n')[:5]:
                                                        if line.strip():
                                                            html += f'<code>- {line.strip()}</code><br>'
                                    
                                    for sitemap_changes in os.listdir(changes_dir):
                                        if sitemap_changes.endswith('_changes.txt') and 'sitemap' in sitemap_changes:
                                            with open(os.path.join(changes_dir, sitemap_changes)) as f:
                                                content = f.read()
                                                if '=== NOUVELLES URLS ===' in content:
                                                    urls = content.split('=== NOUVELLES URLS ===')[1].split('===')[0].strip()
                                                    if urls:
                                                        sitemap_name = sitemap_changes.replace('_changes.txt', '').replace('sitemap_', '')
                                                        html += f'<br><strong>Nouvelles URLs dans {sitemap_name}:</strong><br>'
                                                        for url in urls.split('\n')[:3]:
                                                            if url.strip():
                                                                html += f'<code>+ {url.strip()}</code><br>'
                                
                                html += '</div>'
                            
                            html += '</div>'
                            
            if (with_errors > 0 or with_changes > 0) and '</div>' not in html.split('<h2>Détails par site</h2>')[-1]:
                html += '<p><em>Détails en cours d\'analyse ou non disponibles pour cette exécution.</em></p>'
        else:
            html += '<p><em>Aucun rapport disponible pour cette exécution.</em></p>'
        
        html += f"""
            <div class="footer">
                <p>
                    <strong>Actions GitHub:</strong> 
                   <a href="https://github.com/{os.environ.get('GITHUB_REPOSITORY', '')}/actions/runs/{os.environ.get('GITHUB_RUN_ID', '')}">
                        Voir les détails complets
                    </a>
                </p>
                <p>Prochaine vérification automatique dans 12 heures</p>
                <p><em>Pour désactiver les notifications, modifiez le workflow dans GitHub</em></p>
            </div>
        </body>
        </html>
        """
        
        print("Envoi de l'email...")
        message = MIMEMultipart()
        message["Subject"] = subject
        message["From"] = sender
        message["To"] = receiver
        message.attach(MIMEText(html, "html"))
        
        try:
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(sender, password)
            server.sendmail(sender, receiver, message.as_string())
            server.quit()
            print(f"Email envoyé à {receiver}")
            print(f"   Sujet: {subject}")
        except Exception as e:
            print(f"Erreur envoi email: {e}")
            exit(1)
        PYTHON
