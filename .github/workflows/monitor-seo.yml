name: Monitor SEO Multi-Sites

on:
  schedule:
    - cron: '0 8,20 * * *'
  workflow_dispatch:
    inputs:
      site_filter:
        description: 'Nom du site à tester (vide = tous)'
        required: false
        default: ''
      force_alert:
        description: 'Forcer envoi email'
        required: false
        default: 'false'

env:
  EMAIL_USERNAME: 'vbouvier.redactrice@gmail.com'
  EMAIL_PASSWORD: 'avrf enpz otim qlnf'
  NOTIFICATION_EMAIL: 'vbouvier@cybercite.fr'

jobs:
  setup:
    name: Configuration
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      sites_count: ${{ steps.set-matrix.outputs.count }}
    
    steps:
    - name: Configure sites matrix
      id: set-matrix
      run: |
        SITES_JSON=$(cat << 'EOF'
        {
          "sites": [
            {
              "name": "Brown Shipley",
              "url": "https://brownshipley.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["en-gb/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Orange Caraibe",
              "url": "https://caraibe.orange.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Recrutement FHSJ",
              "url": "https://recrutement-fhsj.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Assuropoil",
              "url": "https://www.assuropoil.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Avoriaz",
              "url": "https://www.avoriaz.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Domicile Clean",
              "url": "https://www.domicile-clean.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Espaces Atypiques",
              "url": "https://www.espaces-atypiques.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Hopital Marie Lannelongue",
              "url": "https://www.hopitalmarielannelongue.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "HPSJ",
              "url": "https://www.hpsj.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "InsingerGilissen",
              "url": "https://www.insingergilissen.nl/",
              "robots_path": "nl-nl/robots.txt",
              "sitemaps": ["nl-nl/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "International Patient Paris",
              "url": "https://www.international-patient-paris.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Le Voyage a Nantes",
              "url": "https://www.levoyageanantes.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Macoretz",
              "url": "https://www.macoretz.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Merck Finck",
              "url": "https://www.merckfinck.de/",
              "robots_path": "robots.txt",
              "sitemaps": ["de-de/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "NDBS",
              "url": "https://www.ndbs.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Pharmapets BE",
              "url": "https://www.pharmapets.be/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/pharmapets_be/sitemap_nl_product.xml",
                "media/sitemaps/pharmapets_be/sitemap_fr_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Pharmapets NL",
              "url": "https://www.pharmapets.nl/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/pharmapets_nl/sitemap_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Puilaetco",
              "url": "https://www.puilaetco.be/",
              "robots_path": "robots.txt",
              "sitemaps": ["fr-be/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Quintet COM",
              "url": "https://www.quintet.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["en-gb/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Quintet LU",
              "url": "https://www.quintet.lu/",
              "robots_path": "robots.txt",
              "sitemaps": ["en-lu/sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Royan Atlantique",
              "url": "https://www.royanatlantique.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap_index.xml"],
              "enabled": true
            },
            {
              "name": "Sayse",
              "url": "https://www.sayse.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Terre de Marins",
              "url": "https://www.terredemarins.fr/",
              "robots_path": "robots.txt",
              "sitemaps": ["1_fr_0_sitemap.xml"],
              "enabled": true
            },
            {
              "name": "Tom and Co",
              "url": "https://www.tomandco.com/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/tomandco/sitemap_tc_benl_product.xml",
                "media/sitemaps/tomandco/sitemap_tc_befr_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Vetostore",
              "url": "https://www.vetostore.com/",
              "robots_path": "robots.txt",
              "sitemaps": [
                "media/sitemaps/vetostore/sitemap_product.xml"
              ],
              "enabled": true
            },
            {
              "name": "Lea Nature",
              "url": "https://www.leanature.com/",
              "robots_path": "robots.txt",
              "sitemaps": ["media/google_sitemap_3.xml"],
              "enabled": true
            }
          ]
        }
        EOF
        )
        
        if [ -n "${{ github.event.inputs.site_filter }}" ]; then
          FILTERED=$(echo "$SITES_JSON" | jq -c --arg filter "${{ github.event.inputs.site_filter }}" '.sites | map(select(.name | test($filter; "i")) | select(.enabled == true))')
        else
          FILTERED=$(echo "$SITES_JSON" | jq -c '.sites | map(select(.enabled == true))')
        fi
        
        echo "matrix={\"include\":$FILTERED}" >> $GITHUB_OUTPUT
        COUNT=$(echo "$FILTERED" | jq '. | length')
        echo "count=$COUNT" >> $GITHUB_OUTPUT
        echo "$COUNT sites configurés"

  # ========================================
  # MONITORING PARALLÈLE
  # ========================================
  monitor:
    name: 🔍 ${{ matrix.name }}
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}
      max-parallel: 5
      fail-fast: false
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup
      run: |
        SAFE_NAME=$(echo "${{ matrix.name }}" | sed 's/[^a-zA-Z0-9]/_/g' | tr '[:upper:]' '[:lower:]')
        echo "SAFE_NAME=${SAFE_NAME}" >> $GITHUB_ENV
        mkdir -p "data/${SAFE_NAME}"
        mkdir -p "history/${SAFE_NAME}"
        mkdir -p "changes/${SAFE_NAME}"
    
    - name: Download robots.txt
      id: robots
      run: |
        URL="${{ matrix.url }}${{ matrix.robots_path }}"
        echo "📥 Robots.txt: $URL"
        
        HTTP_STATUS=$(curl -s -o "data/${SAFE_NAME}/robots.txt" -w "%{http_code}" -L "$URL" \
          -H "User-Agent: Mozilla/5.0 (compatible; SEOMonitor/1.0)" \
          --max-time 30)
        
        if [ "$HTTP_STATUS" -eq 200 ]; then
          echo "✅ OK ($(wc -l < data/${SAFE_NAME}/robots.txt) lignes)"
          echo "status=success" >> $GITHUB_OUTPUT
        else
          echo "❌ Erreur HTTP $HTTP_STATUS"
          echo "status=error" >> $GITHUB_OUTPUT
          echo "error=HTTP $HTTP_STATUS" >> $GITHUB_OUTPUT
        fi
    
    - name: Download sitemaps
      id: sitemaps
      run: |
        echo "📥 Téléchargement des sitemaps..."
        ALL_SUCCESS=true
        ERRORS=""
        
        # Créer un fichier temporaire pour les résultats
        echo "success" > /tmp/sitemap_status.txt
        echo "" > /tmp/sitemap_errors.txt
        
        echo '${{ toJson(matrix.sitemaps) }}' | jq -r '.[]' | while IFS= read -r sitemap; do
          URL="${{ matrix.url }}${sitemap}"
          FILENAME=$(echo "$sitemap" | sed 's/\//_/g')
          
          echo "  → $URL"
          HTTP_STATUS=$(curl -s -o "data/${SAFE_NAME}/sitemap_${FILENAME}" -w "%{http_code}" -L "$URL" \
            -H "User-Agent: Mozilla/5.0 (compatible; SEOMonitor/1.0)" \
            --max-time 30)
          
          if [ "$HTTP_STATUS" -eq 200 ]; then
            echo "    ✅ OK ($(wc -c < data/${SAFE_NAME}/sitemap_${FILENAME}) bytes)"
          else
            echo "    ❌ Erreur HTTP $HTTP_STATUS"
            echo "error" > /tmp/sitemap_status.txt
            echo "${sitemap}:${HTTP_STATUS};" >> /tmp/sitemap_errors.txt
          fi
        done
        
        # Lire les résultats depuis les fichiers temporaires
        STATUS=$(cat /tmp/sitemap_status.txt)
        ERRORS=$(cat /tmp/sitemap_errors.txt | tr -d '\n')
        
        echo "status=$STATUS" >> $GITHUB_OUTPUT
        echo "errors=$ERRORS" >> $GITHUB_OUTPUT
    
    - name: Setup initial state
      id: setup_state
      run: |
        echo "🔄 Initialisation de l'état..."
        
        # Créer les dossiers nécessaires
        mkdir -p "history/${SAFE_NAME}"
        mkdir -p "temp_history"
        
        # Tentative de récupération de l'historique via l'API GitHub
        echo "📡 Recherche d'historique existant..."
        
        # Récupérer la liste des artifacts récents
        ARTIFACTS_RESPONSE=$(curl -s -H "Authorization: Bearer ${{ github.token }}" \
          "https://api.github.com/repos/${{ github.repository }}/actions/artifacts?per_page=100" || echo '{"artifacts":[]}')
        
        # Chercher notre artifact spécifique
        ARTIFACT_ID=$(echo "$ARTIFACTS_RESPONSE" | jq -r --arg name "history-${SAFE_NAME}" \
          '.artifacts[] | select(.name == $name and .expired == false) | .id' | head -1)
        
        if [ "$ARTIFACT_ID" != "" ] && [ "$ARTIFACT_ID" != "null" ]; then
          echo "📂 Artifact historique trouvé (ID: $ARTIFACT_ID)"
          
          # Télécharger l'artifact directement via l'API
          DOWNLOAD_URL=$(curl -s -H "Authorization: Bearer ${{ github.token }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID/zip" \
            -w "%{url_effective}" -o "temp_history/history.zip")
          
          if [ -f "temp_history/history.zip" ] && [ -s "temp_history/history.zip" ]; then
            cd temp_history
            unzip -q history.zip 2>/dev/null || echo "Erreur extraction"
            cd ..
            
            # Copier les fichiers extraits
            if [ -d "temp_history" ]; then
              cp -r temp_history/* "history/${SAFE_NAME}/" 2>/dev/null || true
            fi
            
            echo "✅ Historique restauré avec succès"
            echo "has_history=true" >> $GITHUB_OUTPUT
          else
            echo "⚠️ Échec du téléchargement de l'historique"
            echo "has_history=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "🆕 Aucun historique trouvé - première exécution"
          echo "has_history=false" >> $GITHUB_OUTPUT
        fi
        
        # Nettoyer les fichiers temporaires
        rm -rf temp_history
    
    - name: Determine execution type
      id: execution_type
      run: |
        if [ "${{ steps.setup_state.outputs.has_history }}" = "true" ] && [ -f "history/${SAFE_NAME}/robots.txt" ]; then
          echo "📊 Historique valide trouvé"
          echo "is_first_run=false" >> $GITHUB_OUTPUT
        else
          echo "🆕 Première exécution (pas d'historique valide)"
          echo "is_first_run=true" >> $GITHUB_OUTPUT
        fi
    
    - name: Check for changes
      id: changes
      run: |
        echo "🔍 Analyse des changements..."
        
        IS_FIRST_RUN="${{ steps.execution_type.outputs.is_first_run }}"
        HAS_CHANGES=false
        CHANGES_DETAILS=""
        
        if [ "$IS_FIRST_RUN" = "true" ]; then
          echo "🆕 Première vérification pour ce site"
        else
          echo "📊 Comparaison avec l'historique..."
          
          # Analyser robots.txt
          if [ -f "data/${SAFE_NAME}/robots.txt" ] && [ -f "history/${SAFE_NAME}/robots.txt" ]; then
            if ! diff -q "history/${SAFE_NAME}/robots.txt" "data/${SAFE_NAME}/robots.txt" > /dev/null; then
              HAS_CHANGES=true
              echo "📝 Changements détectés dans robots.txt"
              
              # Créer un diff détaillé
              diff -u "history/${SAFE_NAME}/robots.txt" "data/${SAFE_NAME}/robots.txt" > "changes/${SAFE_NAME}/robots_diff.txt" || true
              
              # Analyser les changements
              ADDED_LINES=$(grep "^+" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^+++" | wc -l || echo 0)
              REMOVED_LINES=$(grep "^-" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^---" | wc -l || echo 0)
              
              # Extraire les règles modifiées
              echo "### ROBOTS.TXT CHANGES ###" > "changes/${SAFE_NAME}/robots_changes.txt"
              echo "Lignes ajoutées: $ADDED_LINES" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "Lignes supprimées: $REMOVED_LINES" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "=== AJOUTS ===" >> "changes/${SAFE_NAME}/robots_changes.txt"
              grep "^+" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^+++" | head -20 >> "changes/${SAFE_NAME}/robots_changes.txt" || true
              echo "" >> "changes/${SAFE_NAME}/robots_changes.txt"
              echo "=== SUPPRESSIONS ===" >> "changes/${SAFE_NAME}/robots_changes.txt"
              grep "^-" "changes/${SAFE_NAME}/robots_diff.txt" | grep -v "^---" | head -20 >> "changes/${SAFE_NAME}/robots_changes.txt" || true
              
              CHANGES_DETAILS="${CHANGES_DETAILS}robots.txt:modified($ADDED_LINES+/$REMOVED_LINES-);"
            fi
          fi
          
          # Analyser chaque sitemap
          for sitemap_file in data/${SAFE_NAME}/sitemap_*; do
            if [ -f "$sitemap_file" ]; then
              BASENAME=$(basename "$sitemap_file")
              
              if [ -f "history/${SAFE_NAME}/$BASENAME" ]; then
                if ! diff -q "$sitemap_file" "history/${SAFE_NAME}/$BASENAME" > /dev/null; then
                  HAS_CHANGES=true
                  echo "📝 Changements dans $BASENAME"
                  
                  # Analyser les URLs pour les sitemaps XML
                  if [[ "$BASENAME" == *".xml" ]]; then
                    # Extraire les URLs avant/après
                    grep -o '<loc>[^<]*</loc>' "history/${SAFE_NAME}/$BASENAME" 2>/dev/null | sed 's/<[^>]*>//g' | sort > "/tmp/old_urls.txt" || touch "/tmp/old_urls.txt"
                    grep -o '<loc>[^<]*</loc>' "$sitemap_file" | sed 's/<[^>]*>//g' | sort > "/tmp/new_urls.txt"
                    
                    # Compter les différences
                    ADDED_URLS=$(comm -13 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | wc -l)
                    REMOVED_URLS=$(comm -23 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | wc -l)
                    
                    # Sauvegarder les détails
                    echo "### $BASENAME CHANGES ###" > "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    echo "URLs ajoutées: $ADDED_URLS" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    echo "URLs supprimées: $REMOVED_URLS" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    echo "" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    
                    if [ $ADDED_URLS -gt 0 ]; then
                      echo "=== NOUVELLES URLS ===" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                      comm -13 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | head -10 >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    fi
                    
                    if [ $REMOVED_URLS -gt 0 ]; then
                      echo "=== URLS SUPPRIMÉES ===" >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                      comm -23 "/tmp/old_urls.txt" "/tmp/new_urls.txt" | head -10 >> "changes/${SAFE_NAME}/${BASENAME}_changes.txt"
                    fi
                    
                    CHANGES_DETAILS="${CHANGES_DETAILS}${BASENAME}:modified($ADDED_URLS+/$REMOVED_URLS-);"
                  fi
                fi
              fi
            fi
          done
        fi
        
        # Output
        echo "is_first_run=$IS_FIRST_RUN" >> $GITHUB_OUTPUT
        echo "has_changes=$HAS_CHANGES" >> $GITHUB_OUTPUT
        echo "details=$CHANGES_DETAILS" >> $GITHUB_OUTPUT
    
    - name: Create detailed report
      id: report
      run: |
        # Créer le rapport JSON
        REPORT_FILE="data/${SAFE_NAME}/report.json"
        
        cat << EOF > "$REPORT_FILE"
        {
          "site": "${{ matrix.name }}",
          "url": "${{ matrix.url }}",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "is_first_run": ${{ steps.changes.outputs.is_first_run }},
          "robots": {
            "status": "${{ steps.robots.outputs.status }}",
            "error": "${{ steps.robots.outputs.error }}"
          },
          "sitemaps": {
            "status": "${{ steps.sitemaps.outputs.status }}",
            "errors": "${{ steps.sitemaps.outputs.errors }}"
          },
          "changes": {
            "has_changes": ${{ steps.changes.outputs.has_changes }},
            "details": "${{ steps.changes.outputs.details }}"
          }
        }
        EOF
        
        # Ajouter les détails des changements si disponibles
        if [ -d "changes/${SAFE_NAME}" ] && [ "$(ls -A changes/${SAFE_NAME})" ]; then
          echo "📄 Détails des changements disponibles"
          tar -czf "data/${SAFE_NAME}/changes.tar.gz" -C "changes/${SAFE_NAME}" .
        fi
        
        # Déterminer si une alerte est nécessaire
        NEEDS_ALERT=false
        if [ "${{ steps.robots.outputs.status }}" = "error" ] || \
           [ "${{ steps.sitemaps.outputs.status }}" = "error" ] || \
           [ "${{ steps.changes.outputs.has_changes }}" = "true" ]; then
          NEEDS_ALERT=true
        fi
        
        echo "needs_alert=$NEEDS_ALERT" >> $GITHUB_OUTPUT
    
    - name: Save history
      if: always()
      run: |
        echo "💾 Sauvegarde de l'état actuel..."
        
        # S'assurer que le dossier history existe toujours
        mkdir -p "history/${SAFE_NAME}"
        
        # Créer un fichier marker pour marquer que ce site a été traité
        echo "$(date -u +%Y-%m-%dT%H:%M:%SZ)" > "history/${SAFE_NAME}/.last_check"
        
        # Sauvegarder robots.txt uniquement si téléchargement réussi
        if [ -f "data/${SAFE_NAME}/robots.txt" ] && [ "${{ steps.robots.outputs.status }}" = "success" ]; then
          cp "data/${SAFE_NAME}/robots.txt" "history/${SAFE_NAME}/robots.txt"
          echo "✅ robots.txt sauvegardé"
        else
          echo "⚠️ robots.txt non sauvegardé (erreur: ${{ steps.robots.outputs.status }})"
        fi
        
        # Sauvegarder les sitemaps
        SITEMAP_COUNT=0
        for sitemap in data/${SAFE_NAME}/sitemap_*; do
          if [ -f "$sitemap" ]; then
            cp "$sitemap" "history/${SAFE_NAME}/"
            SITEMAP_COUNT=$((SITEMAP_COUNT + 1))
          fi
        done
        echo "✅ $SITEMAP_COUNT sitemaps sauvegardés"
        
        # Vérifier que l'historique contient au moins le marker
        if [ -f "history/${SAFE_NAME}/.last_check" ]; then
          echo "✅ Dossier historique prêt pour upload"
          ls -la "history/${SAFE_NAME}/"
        else
          echo "❌ Problème avec la création du dossier historique"
        fi
    
    - name: Upload history
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: history-${{ env.SAFE_NAME }}
        path: history/${{ env.SAFE_NAME }}/
        retention-days: 30
        if-no-files-found: ignore
    
    - name: Upload report and changes
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: report-${{ env.SAFE_NAME }}
        path: |
          data/${{ env.SAFE_NAME }}/report.json
          data/${{ env.SAFE_NAME }}/changes.tar.gz
        retention-days: 7
        if-no-files-found: ignore

  # ========================================
  # NOTIFICATION
  # ========================================
  notify:
    name: 📧 Notification
    needs: [setup, monitor]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Download all reports
      uses: actions/download-artifact@v4
      with:
        pattern: report-*
        path: reports/
      continue-on-error: true
    
    - name: Analyze and prepare notification
      id: analyze
      run: |
        echo "📊 Analyse des rapports..."
        
        TOTAL="${{ needs.setup.outputs.sites_count }}"
        FIRST_RUN=0
        WITH_CHANGES=0
        WITH_ERRORS=0
        NEEDS_EMAIL=false
        
        # Vérifier si le dossier reports existe
        if [ ! -d "reports" ]; then
          echo "⚠️ Aucun rapport téléchargé, création d'un dossier vide"
          mkdir -p reports
        fi
        
        # Analyser chaque rapport
        for report_dir in reports/report-*; do
          # Vérifier si le dossier existe réellement (pas juste le pattern)
          if [ -d "$report_dir" ] && [ -f "$report_dir/report.json" ]; then
            REPORT=$(cat "$report_dir/report.json")
            
            IS_FIRST=$(echo "$REPORT" | jq -r '.is_first_run')
            HAS_CHANGES=$(echo "$REPORT" | jq -r '.changes.has_changes')
            ROBOTS_ERROR=$(echo "$REPORT" | jq -r '.robots.status')
            SITEMAP_ERROR=$(echo "$REPORT" | jq -r '.sitemaps.status')
            
            if [ "$IS_FIRST" = "true" ]; then
              FIRST_RUN=$((FIRST_RUN + 1))
            elif [ "$HAS_CHANGES" = "true" ]; then
              WITH_CHANGES=$((WITH_CHANGES + 1))
              NEEDS_EMAIL=true
            fi
            
            if [ "$ROBOTS_ERROR" = "error" ] || [ "$SITEMAP_ERROR" = "error" ]; then
              WITH_ERRORS=$((WITH_ERRORS + 1))
              NEEDS_EMAIL=true
            fi
            
            # Extraire les changements si disponibles
            if [ -f "$report_dir/changes.tar.gz" ]; then
              mkdir -p "all_changes/$(basename $report_dir)"
              tar -xzf "$report_dir/changes.tar.gz" -C "all_changes/$(basename $report_dir)"
            fi
          fi
        done
        
        # Forcer l'email si demandé
        if [ "${{ github.event.inputs.force_alert }}" = "true" ]; then
          NEEDS_EMAIL=true
        fi
        
        echo "first_run=$FIRST_RUN" >> $GITHUB_OUTPUT
        echo "with_changes=$WITH_CHANGES" >> $GITHUB_OUTPUT
        echo "with_errors=$WITH_ERRORS" >> $GITHUB_OUTPUT
        echo "needs_email=$NEEDS_EMAIL" >> $GITHUB_OUTPUT
        
        # Créer le résumé
        echo "# 📊 Monitoring SEO - Résumé" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Sites surveillés:** $TOTAL" >> $GITHUB_STEP_SUMMARY
        echo "- **Première vérification:** $FIRST_RUN" >> $GITHUB_STEP_SUMMARY
        echo "- **Avec changements:** $WITH_CHANGES" >> $GITHUB_STEP_SUMMARY
        echo "- **Avec erreurs:** $WITH_ERRORS" >> $GITHUB_STEP_SUMMARY

    - name: Send detailed email
      if: steps.analyze.outputs.needs_email == 'true'
      env:
        GITHUB_REPOSITORY: ${{ github.repository }}
        GITHUB_RUN_ID: ${{ github.run_id }}
      run: |
        python3 << 'PYTHON'
        import smtplib
        import json
        import os
        from email.mime.text import MIMEText
        from email.mime.multipart import MIMEMultipart
        from datetime import datetime
        
        print("📧 Préparation de l'email de notification...")
        
        sender = "${{ env.EMAIL_USERNAME }}"
        password = "${{ env.EMAIL_PASSWORD }}"
        receiver = "${{ env.NOTIFICATION_EMAIL }}"
        
        total = int("${{ needs.setup.outputs.sites_count }}")
        first_run = int("${{ steps.analyze.outputs.first_run }}")
        with_changes = int("${{ steps.analyze.outputs.with_changes }}")
        with_errors = int("${{ steps.analyze.outputs.with_errors }}")
        
        print(f"📊 Statistiques: {total} sites, {first_run} premières exécutions, {with_changes} changements, {with_errors} erreurs")        
        # Sujet
        if with_errors > 0:
            subject = f"🚨 SEO Alert - {with_errors} erreur(s) / {total} sites"
        elif with_changes > 0:
            subject = f"📝 SEO Update - {with_changes} changement(s) / {total} sites"
        else:
            subject = f"✅ SEO Check - {total} sites vérifiés"
        
        # Corps HTML
        html = f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; }}
                .header {{ background: #f8f9fa; padding: 20px; border-radius: 5px; }}
                .summary {{ background: #e9ecef; padding: 15px; margin: 20px 0; border-radius: 5px; }}
                .site {{ margin: 20px 0; padding: 15px; border-left: 4px solid #007bff; background: #f9f9f9; }}
                .site-error {{ border-left-color: #dc3545; background: #f8d7da; }}
                .site-changed {{ border-left-color: #ffc107; background: #fff3cd; }}
                .site-new {{ border-left-color: #17a2b8; background: #d1ecf1; }}
                .changes-detail {{ background: white; padding: 10px; margin: 10px 0; border-radius: 3px; font-family: monospace; font-size: 12px; }}
                .footer {{ margin-top: 30px; padding-top: 20px; border-top: 1px solid #dee2e6; color: #6c757d; font-size: 0.9em; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>📊 Monitoring SEO Multi-Sites</h1>
                <p><strong>Date:</strong> {datetime.now().strftime("%d/%m/%Y %H:%M")}</p>
             <p><strong>Repository:</strong> {os.environ.get('GITHUB_REPOSITORY', 'N/A')}</p>
            </div>
            
            <div class="summary">
                <h2>Résumé</h2>
                <ul>
                    <li><strong>Sites surveillés:</strong> {total}</li>
                    <li><strong>Première vérification:</strong> {first_run}</li>
                    <li><strong>Avec changements:</strong> {with_changes}</li>
                    <li><strong>Avec erreurs:</strong> {with_errors}</li>
                </ul>
            </div>
            
            <h2>Détails par site</h2>
        """
        
        # Parcourir les rapports pour les détails
        if os.path.exists("reports"):
            for report_dir in os.listdir("reports"):
                if report_dir.startswith("report-"):
                    report_path = os.path.join("reports", report_dir, "report.json")
                    if os.path.exists(report_path):
                        with open(report_path) as f:
                            report = json.load(f)
                        
                        # Déterminer le statut du site
                        has_errors = (report['robots']['status'] == 'error' or report['sitemaps']['status'] == 'error')
                        has_changes = (report['changes']['has_changes'] == True)
                        is_first_run = report['is_first_run']
                        
                        # Afficher si : erreurs OU changements (même en première exécution)
                        if has_errors or (has_changes and not is_first_run):
                            # Déterminer le style et l'icône
                            if has_errors:
                                if is_first_run:
                                    site_class = 'site-error'
                                    icon = '🚨'  # Erreur lors de la première vérification
                                else:
                                    site_class = 'site-error' 
                                    icon = '❌'  # Erreur lors d'une vérification normale
                            elif has_changes:
                                site_class = 'site-changed'
                                icon = '📝'
                            
                            # Afficher le site
                            html += f'<div class="{site_class}">'
                            if is_first_run and has_errors:
                                html += f'<h3>{icon} {report["site"]} <span style="color: #6c757d; font-size: 0.8em;">(Première vérification)</span></h3>'
                            else:
                                html += f'<h3>{icon} {report["site"]}</h3>'
                            html += f'<p><strong>URL:</strong> <a href="{report["url"]}">{report["url"]}</a></p>'
                            
                            # Détails des erreurs (TOUJOURS afficher, même en première exécution)
                            if report['robots']['status'] == 'error':
                                error_msg = report['robots'].get('error', 'Erreur inconnue')
                                html += f'<p>⚠️ <strong>robots.txt:</strong> {error_msg}</p>'
                            
                            if report['sitemaps']['status'] == 'error':
                                error_msg = report['sitemaps'].get('errors', 'Erreur inconnue')
                                html += f'<p>⚠️ <strong>sitemaps:</strong> {error_msg}</p>'
                            
                            # Détails des changements (seulement si pas première exécution)
                            if has_changes and not is_first_run and report['changes']['details']:
                                html += '<div class="changes-detail">'
                                html += '<strong>Changements détectés:</strong><br>'
                                
                                # Parser les détails
                                details = report['changes']['details']
                                for change in details.split(';'):
                                    if change:
                                        parts = change.split(':')
                                        if len(parts) == 2:
                                            file_name = parts[0]
                                            change_info = parts[1]
                                            
                                            # Extraire les nombres
                                            if 'modified' in change_info and '(' in change_info:
                                                nums = change_info[change_info.find('(')+1:change_info.find(')')].split('/')
                                                if len(nums) == 2:
                                                    added = nums[0].replace('+', '')
                                                    removed = nums[1].replace('-', '')
                                                    
                                                    if file_name == 'robots.txt':
                                                        html += f'<br>📄 <strong>robots.txt:</strong> '
                                                        html += f'{added} lignes ajoutées, {removed} lignes supprimées'
                                                    elif 'sitemap' in file_name:
                                                        html += f'<br>🗺️ <strong>{file_name}:</strong> '
                                                        html += f'{added} URLs ajoutées, {removed} URLs supprimées'
                                
                                # Lire les détails des changements si disponibles
                                changes_dir = f"all_changes/report-{report['site'].replace(' ', '_').lower()}"
                                if os.path.exists(changes_dir):
                                    # Détails robots.txt
                                    robots_changes = os.path.join(changes_dir, "robots_changes.txt")
                                    if os.path.exists(robots_changes):
                                        with open(robots_changes) as f:
                                            content = f.read()
                                            if '=== AJOUTS ===' in content:
                                                adds = content.split('=== AJOUTS ===')[1].split('=== SUPPRESSIONS ===')[0].strip()
                                                if adds:
                                                    html += '<br><br><strong>Lignes ajoutées dans robots.txt:</strong><br>'
                                                    for line in adds.split('\n')[:5]:
                                                        if line.strip():
                                                            html += f'<code>+ {line.strip()}</code><br>'
                                            
                                            if '=== SUPPRESSIONS ===' in content:
                                                dels = content.split('=== SUPPRESSIONS ===')[1].strip()
                                                if dels:
                                                    html += '<br><strong>Lignes supprimées dans robots.txt:</strong><br>'
                                                    for line in dels.split('\n')[:5]:
                                                        if line.strip():
                                                            html += f'<code>- {line.strip()}</code><br>'
                                    
                                    # Détails sitemaps
                                    for sitemap_changes in os.listdir(changes_dir):
                                        if sitemap_changes.endswith('_changes.txt') and 'sitemap' in sitemap_changes:
                                            with open(os.path.join(changes_dir, sitemap_changes)) as f:
                                                content = f.read()
                                                if '=== NOUVELLES URLS ===' in content:
                                                    urls = content.split('=== NOUVELLES URLS ===')[1].split('===')[0].strip()
                                                    if urls:
                                                        sitemap_name = sitemap_changes.replace('_changes.txt', '').replace('sitemap_', '')
                                                        html += f'<br><strong>Nouvelles URLs dans {sitemap_name}:</strong><br>'
                                                        for url in urls.split('\n')[:3]:
                                                            if url.strip():
                                                                html += f'<code>+ {url.strip()}</code><br>'
                                
                                html += '</div>'
                            
                            html += '</div>'
                            
            # Si aucun site n'a été affiché mais qu'il y a des erreurs/changements dans les stats
            if (with_errors > 0 or with_changes > 0) and '</div>' not in html.split('<h2>Détails par site</h2>')[-1]:
                html += '<p><em>Détails en cours d\'analyse ou non disponibles pour cette exécution.</em></p>'
        else:
            html += '<p><em>Aucun rapport disponible pour cette exécution.</em></p>'
        
        # Footer
        html += f"""
            <div class="footer">
                <p>
                    <strong>Actions GitHub:</strong> 
                   <a href="https://github.com/{os.environ.get('GITHUB_REPOSITORY', '')}/actions/runs/{os.environ.get('GITHUB_RUN_ID', '')}">
                        Voir les détails complets
                    </a>
                </p>
                <p>Prochaine vérification automatique dans 12 heures</p>
                <p><em>Pour désactiver les notifications, modifiez le workflow dans GitHub</em></p>
            </div>
        </body>
        </html>
        """
        
        # Envoyer l'email
        print("📤 Envoi de l'email...")
        message = MIMEMultipart()
        message["Subject"] = subject
        message["From"] = sender
        message["To"] = receiver
        message.attach(MIMEText(html, "html"))
        
        try:
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(sender, password)
            server.sendmail(sender, receiver, message.as_string())
            server.quit()
            print(f"✅ Email envoyé à {receiver}")
            print(f"   Sujet: {subject}")
        except Exception as e:
            print(f"❌ Erreur envoi email: {e}")
            exit(1)
        PYTHON
